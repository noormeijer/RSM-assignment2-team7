### Description of the data in the generated csv file

## Before parsing (Data collection)
  The data collection phase was conducted by another team. Using Twitter’s API, the team collected 4275 tweets that used one of the following hashtags: #fortnite, #fortniteevent, #astronomical, #travisscot, #travisscottconcert, #travisscottfortnite, #travisscottevent, #fortniteliveevent, #astroworld, #kidcudi and #thescotts. 
  
	The file generated by this collection of tweets, and provided to us, was in a json format. Each json object had a lot of elements, as mentioned in the readme file provided by that team. Both files can be found in the data folder of this workflow. 

	For the data preparation phase, we used this file to, first, parse some of these elements, and second, enrich them using text mining metrics. Both these stages of data preparation were done using a python scrip. 


## Parsing output
	After parsing, a file called parsed-data.csv can be found under the generated folder of this workflow. We parsed the elements ‘tweet’s id’, ‘created_at' and ‘text’ form each tweet. These are the elements we found relevant for our analysis. 
# id
  The tweet’s id is the unique value that represents each tweet.
# created_at
  Provides information about the time each tweet was created, including day and exact hour.
# text
  Body of the tweet itself, the message Twitter users decided to share about the event. 


## Text mining output
# retweet
	Using the parsed text, we started by listing the original tweets and the retweets. This information can be seen under the column ‘retweet’, a binary variable with values True or False.  
# hour, period
	Using the parsed time, we converted the hour to a numeric value so it could be manipulated. We used this column to also create a new column called ‘period’, where we distinguished tweets that were created before, during and after the concert. 
# language
	We used the langdetect library in python to extract information about the language each tweet was written in. 
# polarity, subjectivity
	A sentiment analysis was conducted, making use of the TextBlob library for python, providing polarity and subjectivity scores for each tweet. Polarity is a float between range [-1,1 ] and Subjectivity is a float between range [0,1], where 0 is very objective text and 1 is very subjective text. 
# nwords, goodwords
	‘Nwords' represents the total number of words in a tweet and ‘goodwords’ represents the total number of good words in a tweet, based on a previously created list of good words that include the following: spectacular, good, great, best, goat, incredible, amazing, crazy, insane and fire. The purpose was to find positive tweets about the event, that might be overlooked with a simple sentiment analysis, since some of the words in this list are not usually defined as positive words, but in the context of talking about an event, they represent a good/positive opinion about it. 
# score, negative_score, positive_score, neutral_score, compound_score
	Finally, we used the vaderSentiment package to conduct sentiment analysis again. For each tweet, 4 scores for sentiment analysis were generated, which we divided into 4 different variables to facilitate analysis. Each one of the first three scores, negative, positive and neutral, are floats between 0 and 1 and the compound score is a float between -1 and 1. 

